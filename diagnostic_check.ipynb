{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3e6bd7",
   "metadata": {},
   "source": [
    "# üîç CropShield AI - Pre-Training Diagnostic Check\n",
    "\n",
    "**Purpose**: Verify dataset loading, GPU availability, and data pipeline before CNN model training\n",
    "\n",
    "This notebook checks:\n",
    "1. ‚úÖ DataLoader functionality (FastImageFolder or WebDataset)\n",
    "2. ‚úÖ Tensor shapes, dtypes, and label mappings\n",
    "3. ‚úÖ Image visualization with class names\n",
    "4. ‚úÖ Loading performance (throughput measurement)\n",
    "5. ‚úÖ GPU accessibility and CUDA configuration\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d89dd6",
   "metadata": {},
   "source": [
    "## üì¶ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b35952",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA availability\n",
    "print(\"=\"*80)\n",
    "print(\"GPU DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"\\nüéÆ CUDA Available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    print(f\"   GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"   Current Device: cuda:{torch.cuda.current_device()}\")\n",
    "    \n",
    "    # Memory info\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "    cached = torch.cuda.memory_reserved(0) / (1024**3)\n",
    "    \n",
    "    print(f\"\\nüíæ GPU Memory:\")\n",
    "    print(f\"   Total: {total_memory:.2f} GB\")\n",
    "    print(f\"   Allocated: {allocated:.3f} GB\")\n",
    "    print(f\"   Cached: {cached:.3f} GB\")\n",
    "    print(f\"   Free: {total_memory - cached:.2f} GB\")\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    print(\"\\n‚úÖ GPU ready for training!\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\\n‚ö†Ô∏è  GPU not available, using CPU\")\n",
    "    print(\"   Training will be slower without GPU\")\n",
    "\n",
    "print(f\"\\nüéØ Using device: {device}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829cdeb1",
   "metadata": {},
   "source": [
    "## üìÅ Choose DataLoader Type\n",
    "\n",
    "Select which optimized loader to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "USE_WEBDATASET = True  # Set to False to use FastImageFolder\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0  # Use 0 for Windows, 12 for Linux/Mac\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATALOADER CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Loader type: {'WebDataset' if USE_WEBDATASET else 'FastImageFolder'}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Num workers: {NUM_WORKERS}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81eccb7",
   "metadata": {},
   "source": [
    "## üîÑ Load DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì¶ Creating DataLoader...\")\n",
    "\n",
    "if USE_WEBDATASET:\n",
    "    # Use WebDataset\n",
    "    if not Path('shards/').exists():\n",
    "        print(\"‚ùå ERROR: shards/ directory not found!\")\n",
    "        print(\"   Run: python scripts/create_webdataset_shards.py\")\n",
    "        raise FileNotFoundError(\"shards/ directory not found\")\n",
    "    \n",
    "    from webdataset_loader import make_webdataset_loaders\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_info = make_webdataset_loaders(\n",
    "        shards_dir='shards/',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    classes = class_info['classes']\n",
    "    num_classes = class_info['num_classes']\n",
    "    \n",
    "else:\n",
    "    # Use FastImageFolder\n",
    "    if not Path('Database_resized/').exists():\n",
    "        print(\"‚ùå ERROR: Database_resized/ directory not found!\")\n",
    "        print(\"   Run: python scripts/resize_images.py\")\n",
    "        raise FileNotFoundError(\"Database_resized/ directory not found\")\n",
    "    \n",
    "    from fast_dataset import make_loaders\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_to_idx, classes = make_loaders(\n",
    "        data_dir='Database_resized/',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    num_classes = len(classes)\n",
    "\n",
    "print(f\"\\n‚úÖ DataLoader created successfully!\")\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"   Number of classes: {num_classes}\")\n",
    "print(f\"   Classes (first 5): {classes[:5]}\")\n",
    "print(f\"   Classes (last 5): {classes[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410c526",
   "metadata": {},
   "source": [
    "## üß™ Load One Batch and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6075ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"BATCH ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load one batch with timing\n",
    "print(\"\\n‚è±Ô∏è  Loading batch...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Get first batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Batch loaded in {load_time:.3f} seconds\")\n",
    "\n",
    "# Analyze batch\n",
    "print(f\"\\nüì¶ Tensor Information:\")\n",
    "print(f\"   Images shape: {images.shape}\")\n",
    "print(f\"   Images dtype: {images.dtype}\")\n",
    "print(f\"   Labels shape: {labels.shape}\")\n",
    "print(f\"   Labels dtype: {labels.dtype}\")\n",
    "\n",
    "print(f\"\\nüìä Value Ranges:\")\n",
    "print(f\"   Image min: {images.min():.3f}\")\n",
    "print(f\"   Image max: {images.max():.3f}\")\n",
    "print(f\"   Image mean: {images.mean():.3f}\")\n",
    "print(f\"   Image std: {images.std():.3f}\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è  Label Information:\")\n",
    "print(f\"   Label min: {labels.min()}\")\n",
    "print(f\"   Label max: {labels.max()}\")\n",
    "print(f\"   Unique labels in batch: {torch.unique(labels).tolist()}\")\n",
    "\n",
    "# Calculate throughput\n",
    "batch_size_actual = images.size(0)\n",
    "throughput = batch_size_actual / load_time\n",
    "\n",
    "print(f\"\\nüöÄ Performance:\")\n",
    "print(f\"   Batch size: {batch_size_actual}\")\n",
    "print(f\"   Load time: {load_time:.3f}s\")\n",
    "print(f\"   Throughput: {throughput:.1f} images/second\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff128b",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Sample Label Mapping\n",
    "\n",
    "Show class names for first 8 labels in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bdd7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LABEL MAPPING (First 8 samples)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(min(8, len(labels))):\n",
    "    label_idx = labels[i].item()\n",
    "    class_name = classes[label_idx]\n",
    "    print(f\"   Sample {i+1}: Label {label_idx:2d} ‚Üí {class_name}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6161537f",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Visualize Sample Images\n",
    "\n",
    "Display a grid of 8 images with their class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1759cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "    \"\"\"\n",
    "    Denormalize image tensor from ImageNet normalization\n",
    "    \"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    # Denormalize\n",
    "    img = tensor * std + mean\n",
    "    \n",
    "    # Clip to [0, 1]\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def show_batch(images, labels, classes, num_images=8):\n",
    "    \"\"\"\n",
    "    Display a grid of images with class names\n",
    "    \"\"\"\n",
    "    num_images = min(num_images, len(images))\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Get image and label\n",
    "        img = images[i]\n",
    "        label_idx = labels[i].item()\n",
    "        class_name = classes[label_idx]\n",
    "        \n",
    "        # Denormalize image\n",
    "        img = denormalize(img)\n",
    "        \n",
    "        # Convert to numpy and transpose to (H, W, C)\n",
    "        img_np = img.cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # Display\n",
    "        axes[i].imshow(img_np)\n",
    "        axes[i].set_title(f\"{class_name}\\n(Label: {label_idx})\", fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Images from Training Batch', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Display sample images\n",
    "print(\"\\nüñºÔ∏è  Displaying sample images...\\n\")\n",
    "show_batch(images, labels, classes, num_images=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9f734",
   "metadata": {},
   "source": [
    "## ‚ö° GPU Transfer Test\n",
    "\n",
    "Test moving data to GPU (if available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GPU TRANSFER TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if cuda_available:\n",
    "    print(\"\\n‚è±Ô∏è  Testing GPU transfer speed...\")\n",
    "    \n",
    "    # Test pinned memory transfer\n",
    "    start_time = time.time()\n",
    "    images_gpu = images.to(device, non_blocking=True)\n",
    "    labels_gpu = labels.to(device, non_blocking=True)\n",
    "    torch.cuda.synchronize()  # Wait for transfer to complete\n",
    "    transfer_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Transfer complete in {transfer_time*1000:.2f}ms\")\n",
    "    \n",
    "    # Check memory usage\n",
    "    allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "    cached = torch.cuda.memory_reserved(0) / (1024**3)\n",
    "    \n",
    "    print(f\"\\nüíæ GPU Memory After Transfer:\")\n",
    "    print(f\"   Allocated: {allocated:.3f} GB\")\n",
    "    print(f\"   Cached: {cached:.3f} GB\")\n",
    "    \n",
    "    # Verify data on GPU\n",
    "    print(f\"\\n‚úÖ Data on GPU:\")\n",
    "    print(f\"   Images device: {images_gpu.device}\")\n",
    "    print(f\"   Labels device: {labels_gpu.device}\")\n",
    "    \n",
    "    # Estimate batch transfer speed\n",
    "    batch_size_mb = (images.numel() * images.element_size()) / (1024**2)\n",
    "    transfer_speed = batch_size_mb / transfer_time\n",
    "    \n",
    "    print(f\"\\nüöÄ Transfer Performance:\")\n",
    "    print(f\"   Batch size: {batch_size_mb:.2f} MB\")\n",
    "    print(f\"   Transfer speed: {transfer_speed:.1f} MB/s\")\n",
    "    \n",
    "    # Clean up GPU memory\n",
    "    del images_gpu, labels_gpu\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GPU available, skipping transfer test\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a0d61",
   "metadata": {},
   "source": [
    "## üìä Multi-Batch Loading Test\n",
    "\n",
    "Test loading multiple batches to measure sustained throughput:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7fc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MULTI-BATCH LOADING TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "NUM_TEST_BATCHES = 10\n",
    "print(f\"\\n‚è±Ô∏è  Loading {NUM_TEST_BATCHES} batches...\")\n",
    "\n",
    "start_time = time.time()\n",
    "batch_times = []\n",
    "total_images = 0\n",
    "\n",
    "for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "    batch_start = time.time()\n",
    "    \n",
    "    # Simulate processing (move to GPU if available)\n",
    "    if cuda_available:\n",
    "        batch_images = batch_images.to(device, non_blocking=True)\n",
    "        batch_labels = batch_labels.to(device, non_blocking=True)\n",
    "    \n",
    "    batch_time = time.time() - batch_start\n",
    "    batch_times.append(batch_time)\n",
    "    total_images += batch_images.size(0)\n",
    "    \n",
    "    if i + 1 >= NUM_TEST_BATCHES:\n",
    "        break\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "avg_batch_time = np.mean(batch_times)\n",
    "std_batch_time = np.std(batch_times)\n",
    "throughput = total_images / total_time\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {NUM_TEST_BATCHES} batches ({total_images} images)\")\n",
    "\n",
    "print(f\"\\nüìä Loading Statistics:\")\n",
    "print(f\"   Total time: {total_time:.3f}s\")\n",
    "print(f\"   Avg batch time: {avg_batch_time*1000:.1f}ms ¬± {std_batch_time*1000:.1f}ms\")\n",
    "print(f\"   Min batch time: {min(batch_times)*1000:.1f}ms\")\n",
    "print(f\"   Max batch time: {max(batch_times)*1000:.1f}ms\")\n",
    "\n",
    "print(f\"\\nüöÄ Sustained Throughput:\")\n",
    "print(f\"   {throughput:.1f} images/second\")\n",
    "print(f\"   {throughput/BATCH_SIZE:.2f} batches/second\")\n",
    "\n",
    "# Estimate epoch time\n",
    "if USE_WEBDATASET:\n",
    "    train_samples = 17901  # From metadata\n",
    "else:\n",
    "    # Estimate from loader\n",
    "    train_samples = 17909  # Approximate (80% of 22387)\n",
    "\n",
    "epoch_time = train_samples / throughput\n",
    "print(f\"\\n‚è±Ô∏è  Estimated Training Time:\")\n",
    "print(f\"   Samples per epoch: {train_samples}\")\n",
    "print(f\"   Time per epoch: {epoch_time:.1f}s ({epoch_time/60:.2f} minutes)\")\n",
    "print(f\"   Time for 50 epochs: {epoch_time*50/60:.1f} minutes ({epoch_time*50/3600:.2f} hours)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750982b",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Diagnostic Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check all systems\n",
    "checks = [\n",
    "    (\"‚úÖ\", \"PyTorch installed\", f\"v{torch.__version__}\"),\n",
    "    (\"‚úÖ\" if cuda_available else \"‚ö†Ô∏è \", \"GPU available\", \n",
    "     f\"{torch.cuda.get_device_name(0)}\" if cuda_available else \"CPU only\"),\n",
    "    (\"‚úÖ\", \"DataLoader created\", f\"{'WebDataset' if USE_WEBDATASET else 'FastImageFolder'}\"),\n",
    "    (\"‚úÖ\", \"Batch loading works\", f\"{BATCH_SIZE} images/batch\"),\n",
    "    (\"‚úÖ\", \"Tensor shapes correct\", f\"{images.shape}\"),\n",
    "    (\"‚úÖ\", \"Labels valid\", f\"Range: {labels.min()}-{labels.max()}\"),\n",
    "    (\"‚úÖ\", \"Image normalization\", f\"Mean: {images.mean():.3f}, Std: {images.std():.3f}\"),\n",
    "    (\"‚úÖ\", \"Throughput measured\", f\"{throughput:.1f} img/s\"),\n",
    "]\n",
    "\n",
    "print(\"\\nüìã System Checks:\")\n",
    "for status, check, detail in checks:\n",
    "    print(f\"   {status} {check:<30} {detail}\")\n",
    "\n",
    "print(\"\\nüìä Dataset Configuration:\")\n",
    "print(f\"   Number of classes: {num_classes}\")\n",
    "print(f\"   Training samples: ~{train_samples:,}\")\n",
    "print(f\"   Image size: 224√ó224√ó3\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Num workers: {NUM_WORKERS}\")\n",
    "\n",
    "print(\"\\nüöÄ Performance:\")\n",
    "print(f\"   Data loading: {throughput:.1f} img/s\")\n",
    "print(f\"   Epoch time: ~{epoch_time/60:.2f} minutes\")\n",
    "print(f\"   50 epochs: ~{epoch_time*50/60:.1f} minutes\")\n",
    "\n",
    "if cuda_available:\n",
    "    print(f\"\\nüíæ GPU Memory:\")\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"   Total: {total_memory:.2f} GB\")\n",
    "    print(f\"   Available for training: ~{total_memory*0.9:.2f} GB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ ALL DIAGNOSTICS PASSED!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ Ready for CNN Model Training!\\n\")\n",
    "print(\"Next steps:\")\n",
    "print(\"   1. Build CNN model architecture (ResNet50, EfficientNet, or custom)\")\n",
    "print(\"   2. Create training script with this optimized DataLoader\")\n",
    "print(\"   3. Add mixed precision training (AMP) for faster GPU utilization\")\n",
    "print(\"   4. Implement learning rate scheduling and early stopping\")\n",
    "print(\"   5. Monitor training with TensorBoard\")\n",
    "print(\"\\nüöÄ Let's build that model!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
